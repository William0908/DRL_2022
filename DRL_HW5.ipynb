{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRL_HW5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsRAs0r2LM4F"
      },
      "source": [
        "# **掛載雲端硬碟**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Palgjg3BtPF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrloB99LV00"
      },
      "source": [
        "# **安裝相關套件**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AxnvAVyzQQ"
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2CE3TOS1ij3"
      },
      "source": [
        "!pip install stable_baselines3 gym box2d-py tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Open AI GYM的2D box** **並選用Cart Pole進行遊戲訓練** "
      ],
      "metadata": {
        "id": "FRK2j2t2PW9w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXSx7hg19TH"
      },
      "source": [
        " Imports and Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb2JwZy4jGj"
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEtc28G4niA"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vg5Iing2oXX"
      },
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9UWeToN4r7D"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "game = \"CartPole-v1\" \n",
        "def show_video(): # 將video在網頁上展示\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True) # 以monitor函數監控訓練結果\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3BGbWOu179M"
      },
      "source": [
        "# **Cart Pole**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEFMfDOzLen"
      },
      "source": [
        "#env = wrap_env(gym.make(\"MsPacman-v0\"))\n",
        "env = wrap_env(gym.make(game))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmIlXhe9Q89"
      },
      "source": [
        "#check out the pacman action space!\n",
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbFd2iNMLdMk"
      },
      "source": [
        "### **測試環境**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nj5sjsk15IT"
      },
      "source": [
        "observation = env.reset() # 以隨機策略測試環境,並將reward印出來\n",
        "reward = 0\n",
        "while True:\n",
        "  \n",
        "    env.render()\n",
        "    \n",
        "    #your agent goes here\n",
        "    action = env.action_space.sample() \n",
        "         \n",
        "    observation, rewards, done, info = env.step(action) \n",
        "    reward += rewards\n",
        "        \n",
        "    if done: \n",
        "      break;\n",
        "\n",
        "print(reward)  \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbSmNa-1LqSI"
      },
      "source": [
        "# **訓練**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQCpZq_xLqPq"
      },
      "source": [
        "以PPO做為環境model進行訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqNGAuQt3WYm"
      },
      "source": [
        "# env = wrap_env(gym.make(game)) \n",
        "# env = DummyVecEnv([lambda: env])\n",
        "# model = PPO('MlpPolicy', env, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTEwok9O3WZ_"
      },
      "source": [
        "model.learn(total_timesteps=50000) # 設定max_timesteps為50000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kj6SNiC3Wfa"
      },
      "source": [
        "#evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
        "#env.close()\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiRXG3yXLuJZ"
      },
      "source": [
        "# **儲存模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2XWxi7z3WpV"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/deep reinforcement learning/colab/PPO_model\") # 將模型存儲於對應雲端硬碟路徑"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WcnVpNP4ELc"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiUN2t49FJP0"
      },
      "source": [
        "# **測試**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L71gysaL4EIY"
      },
      "source": [
        "model = PPO.load(\"/content/drive/MyDrive/deep reinforcement learning/colab/PPO_model\", env=env) #需更改雲端硬碟路徑"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqxRsf3M4Knh"
      },
      "source": [
        "#env.close()\n",
        "env = wrap_env(gym.make(game))\n",
        "obs = env.reset()\n",
        "done = False\n",
        "reward = 0\n",
        "while not done: # 測試訓練後的結果\n",
        "    action, _states = model.predict(obs.copy())\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    reward+=rewards\n",
        "    env.render()\n",
        "    \n",
        "    #print(info)\n",
        "print(reward)\n",
        "\n",
        "env.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oqsxTVY4D6h"
      },
      "source": [
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練前的reward: 38\n",
        "\n",
        "# 以max_timesteps訓練後的reward: 500\n",
        "\n",
        "# (Baseline需大於475)"
      ],
      "metadata": {
        "id": "iuzbB4h_hicd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Action Space:\n",
        "\n",
        "![1.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "owd_-jk1iqUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rewards\n",
        "\n",
        "Since the goal is to keep the pole upright for as long as possible, a reward of +1 for every step taken, including the termination step, is allotted. The threshold for rewards is **475** for v1."
      ],
      "metadata": {
        "id": "JYFTi7nzi8Ki"
      }
    }
  ]
}
